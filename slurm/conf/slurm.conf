ControlMachine=slc-mst                      # hostname of master node
AuthType=auth/munge                        # authentification with munge
SlurmdPort=6818                            # slurm daemon port
SlurmctldPort=6817                         # slurm controller daemon port 

StateSaveLocation=/var/spool/slurm/state              # at the install time, not yet created
SlurmdSpoolDir=/var/spool/slurm

# 작업 자격 증명에 사용할 키 설정 
JobCredentialPrivateKey=/var/spool/slurm/cred_priv.pem 
JobCredentialPublicCertificate=/var/spool/slurm/cred_pub.pem 
                      
SlurmdLogFile=/var/log/slurm/slurmd.log                    # at the install time, /var/log/slurm exists, slurm directory mode is 777
SlurmctldLogFile=/var/log/slurm/slurmctld.log 
SlurmctldPidFile=/var/log/slurm/slurmctld.pid
SlurmdPidFile=/var/log/slurm/slurmd.pid

ProctrackType=proctrack/cgroup 
ReturnToService=1 
SchedulerType=sched/backfill 

SlurmdTimeout=300 
SlurmctldTimeout=300 
SelectType=select/cons_tres 
SelectTypeParameters=CR_Core_Memory 
TaskPlugin=task/affinity 

ClusterName=workshop

NodeName=slc-wg[1-2] CPUs=4 Boards=1 SocketsPerBoard=1 CoresPerSocket=4 ThreadsPerCore=1 RealMemory=7763     # slurmd -C in worker node

GresTypes=gpu
NodeName=slc-wn[1-2] Gres=gpu:1 CPUs=4 Boards=1 SocketsPerBoard=1 CoresPerSocket=4 ThreadsPerCore=1 RealMemory=7763     # slurmd -C in worker node

PartitionName=graviton Nodes=slc-wg[1-2] Default=YES MaxTime=INFINITE State=UP
PartitionName=nvidia Nodes=slc-wn[1-2] Default=YES MaxTime=INFINITE State=UP

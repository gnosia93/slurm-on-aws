### check nvidia workers ###

```
$ cat ansible_hosts
# modify below ips depending on your cluster ips
[master]
3.36.53.81

[client]
54.180.234.222

[graviton_workers]
43.201.16.173
52.79.153.46

[nvidia_workers]
43.203.201.135
13.125.193.199
```

### 1. compatibility check first ###

Visit https://en.wikipedia.org/wiki/CUDA#GPUs_supported

* find your GPU with Compute Capability, GPU semiconductors and Nvidia GPU board products

![](https://github.com/gnosia93/slurm-on-grv/blob/main/tutorial/images/cuda-1.png)

* find cuda version with Compute Capability (CUDA SDK support vs. Microarchitecture)

![](https://github.com/gnosia93/slurm-on-grv/blob/main/tutorial/images/cuda-2.png)

if you have telsla t4 GPU, Compute capability(version) is 7.5 and find CUDA SDK Version(s) with it.   
here 10.0 â€“ 10.2 is identified as cuda sdk version.   
with this cuda version, find compatible pytorch install version.   

### 2. check cuda toolkit version with pytorch ###
* Vist https://pytorch.org/get-started/locally/ and select options
![](https://github.com/gnosia93/slurm-on-grv/blob/main/slurm/images/pytorch-1.png)

cuda 12.4 is chosen, Therefore, when you run nvcc -V, you should get 12.4.

* Visit https://developer.nvidia.com/cuda-toolkit-archive

![](https://github.com/gnosia93/slurm-on-grv/blob/main/slurm/images/cuda-toolkit-1.png)

and select nvidia cuda toolkit options
![](https://github.com/gnosia93/slurm-on-grv/blob/main/slurm/images/cuda-toolkit-2.png)


### 3. install cuda toolkit ###
```
$ ssh -i aws-kp-2.pem ubuntu@43.203.201.135

ubuntu@slc-wn1:~$ nvidia-smi
Wed Dec 25 17:06:36 2024
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 565.77                 Driver Version: 565.77         CUDA Version: 12.7     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA T4G                     Off |   00000000:00:1F.0 Off |                    0 |
| N/A   45C    P8             10W /   70W |       1MiB /  15360MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+

+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
```
install cuda toolkit 
```
wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa/cuda-ubuntu2204.pin
sudo mv cuda-ubuntu2204.pin /etc/apt/preferences.d/cuda-repository-pin-600
wget https://developer.download.nvidia.com/compute/cuda/12.4.0/local_installers/cuda-repo-ubuntu2204-12-4-local_12.4.0-550.54.14-1_arm64.deb
sudo dpkg -i cuda-repo-ubuntu2204-12-4-local_12.4.0-550.54.14-1_arm64.deb
sudo cp /var/cuda-repo-ubuntu2204-12-4-local/cuda-*-keyring.gpg /usr/share/keyrings/
sudo apt-get update
sudo apt-get -y install cuda-toolkit-12-4
```
confirm installed cuda toolkit version
```
ubuntu@slc-wn1:/usr/local$ ls -la
total 48
drwxr-xr-x 12 root root 4096 Dec 25 17:22 .
drwxr-xr-x 11 root root 4096 Dec 17 02:30 ..
drwxr-xr-x  2 root root 4096 Dec 25 17:22 bin
drwx------  2 root root 4096 Dec 25 15:37 chronicle
lrwxrwxrwx  1 root root   22 Dec 25 17:22 cuda -> /etc/alternatives/cuda
lrwxrwxrwx  1 root root   25 Dec 25 17:22 cuda-12 -> /etc/alternatives/cuda-12
drwxr-xr-x 12 root root 4096 Dec 25 17:22 cuda-12.4
drwxr-xr-x  2 root root 4096 Dec 17 02:30 etc
drwxr-xr-x  2 root root 4096 Dec 17 02:30 games
drwxr-xr-x  2 root root 4096 Dec 17 02:30 include
drwxr-xr-x  3 root root 4096 Dec 17 02:30 lib
lrwxrwxrwx  1 root root    9 Dec 17 02:30 man -> share/man
drwxr-xr-x  2 root root 4096 Dec 17 02:30 sbin
drwxr-xr-x  5 root root 4096 Dec 25 15:38 share
drwxr-xr-x  2 root root 4096 Dec 17 02:30 src
```

edit .profile file
```
vi ~/.profile

export PATH=/usr/local/cuda-12.4/bin:$PATH
export LD_LIBRARY_PATH=/usr/local/cuda-12.4/lib64:$LD_LIBRARY_PATH
```

check toolkit version
```
$ nvcc -V
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2024 NVIDIA Corporation
Built on Tue_Feb_27_16:20:28_PST_2024
Cuda compilation tools, release 12.4, V12.4.99
Build cuda_12.4.r12.4/compiler.33961263_0
```

### 4. [install anaconda](https://docs.anaconda.com/anaconda/install/) ###

```
sudo apt-get install -y libgl1-mesa-glx libegl1-mesa libxrandr2 libxrandr2 libxss1 libxcursor1 libxcomposite1 libasound2 libxi6 libxtst6
curl -O https://repo.anaconda.com/archive/Anaconda3-2024.10-1-Linux-aarch64.sh
bash ~/Anaconda3-2024.10-1-Linux-aarch64.sh
source ~/.bashrc
```

### 5. install pytorch ###
```
conda install pytorch torchvision torchaudio pytorch-cuda=12.4 -c pytorch 
```
```
pip3 install torch torchvision torchaudio
```

```
$ python
Python 3.6.10 |Anaconda, Inc.| (default, May  8 2020, 02:54:21) 
[GCC 7.3.0] on linux
Type "help", "copyright", "credits" or "license" for more information.
>>> import torch
>>> print(torch.cuda.is_available())
True
```

## reference ##

* https://medium.com/@harunijaz/a-step-by-step-guide-to-installing-cuda-with-pytorch-in-conda-on-windows-verifying-via-console-9ba4cd5ccbef

* https://discuss.pytorch.org/t/cant-to-install-pytorch-for-cuda-12-4/200672

* [Compatibility](https://xoft.tistory.com/85) 

